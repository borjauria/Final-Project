{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the libraries to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for webscrapping\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import io\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# REGEX\n",
    "import re\n",
    "\n",
    "# For get the date and time\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "# For create the engine and works with db's\n",
    "import requests\n",
    "from sqlalchemy.types import Integer, Text, String, DateTime\n",
    "from sqlalchemy_utils import create_database, database_exists, drop_database\n",
    "from sqlalchemy import create_engine\n",
    "#import psycopg2\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this function I make the webscrapping I need to extract the data from the tarifaluzahora website\n",
    "def scrapping (tarifa, day = str(date.today())):\n",
    "    \n",
    "    url = 'https://tarifaluzhora.es/?tarifa=' + tarifa\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    \n",
    "    price_ = soup.findAll(\"span\", {\"itemprop\": \"price\"})\n",
    "    hours_ = soup.findAll(\"span\", {\"itemprop\": \"description\"})\n",
    "    \n",
    "    price_hour_ = [price.get_text() for price in price_]\n",
    "    schedule_ = [time.get_text() for time in hours_]\n",
    "    \n",
    "    df = pd.DataFrame.from_dict({'precio':price_hour_,'horario':schedule_})\n",
    "    \n",
    "    df['hora'] = [int(x[:2]) for x in df['horario']]\n",
    "    df['tarifa'] = tarifa\n",
    "    df['precio'] =  [re.sub(r'/[k][W][h]','', str(x)) for x in df['precio']]\n",
    "    df['horario'] =  [re.sub(r'[:]','', str(x)) for x in df['horario']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract fares from scrapping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scrapping('coche_electrico')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(\"precio\").min().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.03203 â‚¬'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precio = df.precio[0]\n",
    "precio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hora = df.hora[0]\n",
    "hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coche_electrico'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tarifa = df.tarifa[0]\n",
    "tarifa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pollas_env",
   "language": "python",
   "name": "pollas_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
