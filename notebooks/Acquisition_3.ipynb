{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the libraries to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for webscrapping\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import io\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# REGEX\n",
    "import re\n",
    "\n",
    "# For get the date and time\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "# For create the engine and works with db's\n",
    "import requests\n",
    "from sqlalchemy.types import Integer, Text, String, DateTime\n",
    "from sqlalchemy_utils import create_database, database_exists, drop_database\n",
    "from sqlalchemy import create_engine\n",
    "#import psycopg2\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this function I make the webscrapping I need to extract the data from the tarifaluzahora website\n",
    "def scrapping (tarifa, day = str(date.today())):\n",
    "    \n",
    "    # Web to scrap\n",
    "    url = 'https://tarifaluzhora.es/?tarifa=' + tarifa\n",
    "    #url = 'https://tarifaluzhora.es/?tarifa=' + tarifa + '&fecha=' + day\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    \n",
    "    # Web scraping to price & description\n",
    "    price_ = soup.findAll(\"span\", {\"itemprop\": \"price\"})\n",
    "    hours_ = soup.findAll(\"span\", {\"itemprop\": \"description\"})\n",
    "    \n",
    "    # Get the values of price & hours with a for loop\n",
    "    price_hour_ = [price.get_text() for price in price_]\n",
    "    schedule_ = [time.get_text() for time in hours_]\n",
    "    \n",
    "    # I've created a dataframe, its name is DF and it has two columns at the moment\n",
    "    df = pd.DataFrame.from_dict({'precio':price_hour_,'horario':schedule_})\n",
    "    \n",
    "    # I have created two more columns, Time contains the 2nd digit of the time column, \n",
    "    # to be able to operate with the hours if necessary.\n",
    "    # ‘Fare' contains the chosen fare\n",
    "    df['hora'] = [int(x[:2]) for x in df['horario']]\n",
    "    df['tarifa'] = tarifa\n",
    "    df['minimo'] = df['precio'].min()\n",
    "    \n",
    "    df['precio'] =  [re.sub(r'/[k][W][h]','', str(x)) for x in df['precio']]\n",
    "    #df['precio'] =  [re.sub(r'\\€\\/[k][W][h]','', str(x)) for x in df['precio']]\n",
    "    df['horario'] =  [re.sub(r'[:]','', str(x)) for x in df['horario']]\n",
    "    #df['minimo'] =  [re.sub(r'\\€\\/[k][W][h]','', str(x)) for x in df['minimo']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract fares from scrapping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scrapping('coche_electrico')\n",
    "df1 = scrapping('normal')\n",
    "df2 = scrapping('discriminacion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frames = [df, df1, df2]\n",
    "#df = pd.concat(frames)\n",
    "#df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.filter(items = ['tarifa', 'precio','hora'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precio = (df.precio.min())\n",
    "#tarifa = (df.tarifa.min())\n",
    "#hora = (df.hora.min())\n",
    "#precio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(\"precio\").min().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El precio más barato es de, 0.03203 € y la hora es a la 1.\n"
     ]
    }
   ],
   "source": [
    "#if df['hora'][0] == 1: \n",
    "#    print(f\"El precio más barato es de, {df.precio[0]} y la hora es a la {df.hora[0]}.\")\n",
    "#else:\n",
    "#    print(f\"El precio más barato es de, {df.precio[0]} y la hora es a las {df.hora[0]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I convert the df to json\n",
    "df3 = df.to_json(orient = 'index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## engine to postgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#engine = create_engine('postgresql+psycopg2://postgres:postgres@localhost:5432/postgres')\n",
    "#df.to_sql('coche_electrico', engine, if_exists = 'replace', index = False)\n",
    "#df1.to_sql('normal', engine, if_exists = 'replace', index = False)\n",
    "#df1.to_sql('discriminacion', engine, if_exists = 'replace', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pollas_env",
   "language": "python",
   "name": "pollas_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
